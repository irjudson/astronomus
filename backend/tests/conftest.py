"""Pytest configuration and shared fixtures for PostgreSQL.

Database fixtures are lazy-loaded to avoid connection failures when running
non-integration tests (e.g., on macOS CI without database services).
"""

import sys
from pathlib import Path

import pytest

# Add app directory to Python path
app_dir = Path(__file__).parent.parent
sys.path.insert(0, str(app_dir))


# ==========================================
# Astronomy Data Pre-loading Fixtures
# ==========================================


@pytest.fixture(scope="session", autouse=True)
def configure_astronomy_data():
    """Pre-download ephemeris data and configure astropy for offline testing.

    This fixture runs once per test session to:
    1. Download de421.bsp ephemeris file (17MB) to avoid timeout issues
    2. Disable automatic IERS data downloads from datacenter.iers.org
    3. Cache data for all tests in the session
    """
    from pathlib import Path

    # Configure Astropy to not download IERS data during tests
    try:
        from astropy.utils import iers

        iers.conf.auto_download = False
        iers.conf.auto_max_age = None
        print("✓ Astropy IERS auto-download disabled")
    except ImportError:
        print("⚠ Astropy not available - IERS configuration skipped")

    # Pre-download Skyfield ephemeris data
    try:
        from skyfield.api import load

        # Create a persistent cache directory
        cache_dir = Path.home() / ".skyfield-data"
        cache_dir.mkdir(exist_ok=True)

        # Configure loader to use cache
        loader = load.Loader(str(cache_dir))

        # Pre-download de421.bsp if not already cached
        ephemeris_path = cache_dir / "de421.bsp"
        if not ephemeris_path.exists():
            print("Downloading ephemeris data (de421.bsp, ~17MB)...")
            loader("de421.bsp")
            print(f"✓ Ephemeris data cached at {ephemeris_path}")
        else:
            print(f"✓ Using cached ephemeris data from {ephemeris_path}")

        # Also download timescale data
        loader.timescale()

    except Exception as e:
        print(f"⚠ Warning: Could not pre-download ephemeris data: {e}")
        print("  Tests requiring ephemeris may timeout")

    yield

    # No cleanup needed - keep cache for future test runs


# Lazy-loaded database components (only initialized when needed)
_test_engine = None
_TestSessionLocal = None


def _get_test_engine():
    """Lazily create the test database engine."""
    global _test_engine
    if _test_engine is None:
        from sqlalchemy import create_engine

        from app.core.config import get_settings

        settings = get_settings()
        TEST_DATABASE_URL = settings.test_database_url
        print(f"TEST_DATABASE_URL in conftest.py: {TEST_DATABASE_URL}")
        _test_engine = create_engine(TEST_DATABASE_URL)
    return _test_engine


def _get_test_session_local():
    """Lazily create the test session factory."""
    global _TestSessionLocal
    if _TestSessionLocal is None:
        from sqlalchemy.orm import sessionmaker

        _TestSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=_get_test_engine())
    return _TestSessionLocal


@pytest.fixture(scope="session")
def setup_test_db_schema():
    """Run Alembic migrations on test database before tests.

    Uses pure Alembic for schema management (no Base.metadata operations).
    This ensures tests run the same migration path as production.

    CRITICAL: We tell Alembic to skip transaction wrappers (use_transaction=False)
    so DDL changes auto-commit and are immediately visible to all database
    connections. This is necessary because PostgreSQL's transactional DDL
    combined with pytest's transaction isolation would otherwise prevent
    tests from seeing the migrated schema.

    Note: When running in parallel with pytest-xdist, all workers share the
    same test database. We run migrations once and let all workers use the
    same schema. Cleanup is NOT done in teardown because it would interfere
    with other workers still running tests.

    This fixture is NOT autouse - it only runs for tests that need database access
    (via the client or override_get_db fixtures).
    """
    from alembic import command
    from alembic.config import Config
    from app.core.config import get_settings

    settings = get_settings()
    TEST_DATABASE_URL = settings.test_database_url

    alembic_cfg = Config("alembic.ini")
    alembic_cfg.set_main_option("sqlalchemy.url", TEST_DATABASE_URL)

    # Tell env.py not to wrap migrations in begin_transaction()
    # This allows DDL to auto-commit in PostgreSQL
    alembic_cfg.attributes["use_transaction"] = False

    # Ensure database is at head revision (idempotent - won't re-run if already at head)
    command.upgrade(alembic_cfg, "head")

    # Load catalog data into test database (skips if already loaded)
    _load_test_catalog_data()

    yield

    # No cleanup - parallel workers share the database
    # Manual cleanup: docker-compose down -v or DROP DATABASE test_astro_planner


def _load_test_catalog_data():
    """Load sample catalog data into test database.

    Creates a minimal set of realistic DSO, constellation, and comet data
    that enables all tests to run without needing a production database.
    """
    from sqlalchemy.orm import Session

    from app.core.config import get_settings
    from app.models.catalog_models import CometCatalog, ConstellationName, DSOCatalog

    settings = get_settings()

    try:
        test_engine = _get_test_engine()

        with test_engine.connect() as conn:
            session = Session(bind=conn)

            # Check if data already loaded
            existing_count = session.query(ConstellationName).count()
            if existing_count > 0:
                print(f"Test catalog data already loaded ({existing_count} constellations)")
                return

            # Sample constellation data (covering objects we'll add)
            constellations = [
                {"abbreviation": "And", "full_name": "Andromeda", "common_name": "Andromeda"},
                {"abbreviation": "Ori", "full_name": "Orion", "common_name": "Orion"},
                {"abbreviation": "Sgr", "full_name": "Sagittarius", "common_name": "Sagittarius"},
                {"abbreviation": "Cyg", "full_name": "Cygnus", "common_name": "Cygnus"},
                {"abbreviation": "Lyr", "full_name": "Lyra", "common_name": "Lyra"},
                {"abbreviation": "Tau", "full_name": "Taurus", "common_name": "Taurus"},
                {"abbreviation": "Gem", "full_name": "Gemini", "common_name": "Gemini"},
                {"abbreviation": "Per", "full_name": "Perseus", "common_name": "Perseus"},
                {"abbreviation": "Vir", "full_name": "Virgo", "common_name": "Virgo"},
                {"abbreviation": "Com", "full_name": "Coma Berenices", "common_name": "Coma Berenices"},
            ]
            session.bulk_insert_mappings(ConstellationName, constellations)

            # Sample DSO data - 10 objects covering different types and catalogs
            dso_objects = [
                # Messier galaxies
                {
                    "catalog_name": "NGC",
                    "catalog_number": 224,
                    "common_name": "M031",
                    "object_type": "galaxy",
                    "ra_hours": 0.712,
                    "dec_degrees": 41.27,
                    "constellation": "And",
                    "magnitude": 3.4,
                    "caldwell_number": None,
                    "size_major_arcmin": 190.0,
                    "size_minor_arcmin": 60.0,
                },
                {
                    "catalog_name": "NGC",
                    "catalog_number": 4486,
                    "common_name": "M087",
                    "object_type": "galaxy",
                    "ra_hours": 12.514,
                    "dec_degrees": 12.39,
                    "constellation": "Vir",
                    "magnitude": 8.6,
                    "caldwell_number": None,
                    "size_major_arcmin": 8.3,
                    "size_minor_arcmin": 6.6,
                },
                # Messier nebulae
                {
                    "catalog_name": "NGC",
                    "catalog_number": 1976,
                    "common_name": "M042",
                    "object_type": "nebula",
                    "ra_hours": 5.588,
                    "dec_degrees": -5.39,
                    "constellation": "Ori",
                    "magnitude": 4.0,
                    "caldwell_number": None,
                    "size_major_arcmin": 85.0,
                    "size_minor_arcmin": 60.0,
                },
                {
                    "catalog_name": "NGC",
                    "catalog_number": 6720,
                    "common_name": "M057",
                    "object_type": "planetary_nebula",
                    "ra_hours": 18.893,
                    "dec_degrees": 33.03,
                    "constellation": "Lyr",
                    "magnitude": 8.8,
                    "caldwell_number": None,
                    "size_major_arcmin": 1.4,
                    "size_minor_arcmin": 1.0,
                },
                # Messier clusters
                {
                    "catalog_name": "NGC",
                    "catalog_number": 1912,
                    "common_name": "M038",
                    "object_type": "cluster",
                    "ra_hours": 5.478,
                    "dec_degrees": 35.85,
                    "constellation": "Gem",
                    "magnitude": 6.4,
                    "caldwell_number": None,
                    "size_major_arcmin": 21.0,
                    "size_minor_arcmin": 21.0,
                },
                {
                    "catalog_name": "NGC",
                    "catalog_number": 6913,
                    "common_name": "M029",
                    "object_type": "cluster",
                    "ra_hours": 20.399,
                    "dec_degrees": 38.52,
                    "constellation": "Cyg",
                    "magnitude": 6.6,
                    "caldwell_number": None,
                    "size_major_arcmin": 7.0,
                    "size_minor_arcmin": 7.0,
                },
                # IC object
                {
                    "catalog_name": "IC",
                    "catalog_number": 434,
                    "common_name": None,
                    "object_type": "nebula",
                    "ra_hours": 5.681,
                    "dec_degrees": -2.46,
                    "constellation": "Ori",
                    "magnitude": 7.3,
                    "caldwell_number": None,
                    "size_major_arcmin": 60.0,
                    "size_minor_arcmin": 10.0,
                },
                # Double Cluster (no Caldwell number to avoid duplicates with full catalog)
                {
                    "catalog_name": "NGC",
                    "catalog_number": 869,
                    "common_name": None,
                    "object_type": "cluster",
                    "ra_hours": 2.317,
                    "dec_degrees": 57.13,
                    "constellation": "Per",
                    "magnitude": 4.3,
                    "caldwell_number": None,
                    "size_major_arcmin": 30.0,
                    "size_minor_arcmin": 30.0,
                },
                {
                    "catalog_name": "NGC",
                    "catalog_number": 1952,
                    "common_name": "M001",
                    "object_type": "nebula",
                    "ra_hours": 5.575,
                    "dec_degrees": 22.01,
                    "constellation": "Tau",
                    "magnitude": 8.4,
                    "caldwell_number": None,
                    "size_major_arcmin": 6.0,
                    "size_minor_arcmin": 4.0,
                },
                # Additional faint object for magnitude filter tests
                {
                    "catalog_name": "NGC",
                    "catalog_number": 4889,
                    "common_name": None,
                    "object_type": "galaxy",
                    "ra_hours": 13.002,
                    "dec_degrees": 27.98,
                    "constellation": "Com",
                    "magnitude": 11.5,
                    "caldwell_number": None,
                    "size_major_arcmin": 2.9,
                    "size_minor_arcmin": 1.9,
                },
            ]
            session.bulk_insert_mappings(DSOCatalog, dso_objects)

            # Sample comet data - use unique designations that won't conflict with test fixtures
            comets = [
                {
                    "designation": "C/2021 TEST1",
                    "name": "Test Comet 1",
                    "epoch_jd": 2459000.5,
                    "perihelion_distance_au": 0.29,
                    "eccentricity": 0.999,
                    "inclination_deg": 128.9,
                    "arg_perihelion_deg": 37.3,
                    "ascending_node_deg": 61.0,
                    "perihelion_time_jd": 2459034.0,
                    "absolute_magnitude": 3.0,
                    "magnitude_slope": 4.0,
                    "current_magnitude": 7.0,
                    "comet_type": "long-period",
                    "activity_status": "active",
                    "data_source": "Test",
                    "notes": "Test comet fixture",
                },
                {
                    "designation": "C/2021 TEST2",
                    "name": "Test Comet 2",
                    "epoch_jd": 2459000.5,
                    "perihelion_distance_au": 1.243,
                    "eccentricity": 0.641,
                    "inclination_deg": 7.04,
                    "arg_perihelion_deg": 12.78,
                    "ascending_node_deg": 50.15,
                    "perihelion_time_jd": 2459131.0,
                    "absolute_magnitude": 11.3,
                    "magnitude_slope": 10.0,
                    "current_magnitude": 12.0,
                    "comet_type": "short-period",
                    "activity_status": "active",
                    "data_source": "Test",
                    "notes": "Test comet fixture",
                },
            ]
            session.bulk_insert_mappings(CometCatalog, comets)

            session.commit()
            print(
                f"Loaded {len(constellations)} constellations, {len(dso_objects)} DSOs, and {len(comets)} comets into test database"
            )

    except Exception as e:
        print(f"Warning: Could not load test catalog data: {e}")
        import traceback

        traceback.print_exc()


@pytest.fixture(scope="function")
def override_get_db(setup_test_db_schema):
    """Override the get_db dependency to use a transactional test session.

    Depends on setup_test_db_schema to ensure migrations are run first.
    """
    from app.database import get_db
    from app.main import app

    test_engine = _get_test_engine()
    TestSessionLocal = _get_test_session_local()

    connection = test_engine.connect()
    transaction = connection.begin()
    db = TestSessionLocal(bind=connection)

    app.dependency_overrides[get_db] = lambda: db

    try:
        yield db
    finally:
        transaction.rollback()
        connection.close()
        app.dependency_overrides.clear()


# Fixture to provide a client that uses the overridden database dependency
@pytest.fixture(scope="function")
def client(override_get_db):
    """Test client that uses the overridden database dependency."""
    from fastapi.testclient import TestClient

    from app.main import app

    with TestClient(app) as c:
        yield c


@pytest.fixture
def temp_db(tmp_path):
    """Create a temporary SQLite database for testing."""
    import shutil

    # Copy the main catalog database to a temp location
    # This ensures all tables (DSO, comet, etc.) are available with correct schema
    source_db = Path(__file__).parent.parent / "data" / "catalogs.db"
    temp_db_path = tmp_path / "test_catalogs.db"
    if source_db.exists():
        shutil.copy(source_db, temp_db_path)
        return str(temp_db_path)
    else:
        # If source doesn't exist, tests will fail - this is intentional
        # as it indicates the catalog database hasn't been set up
        raise FileNotFoundError(
            f"Catalog database not found at {source_db}. Run scripts/import_catalog.py and scripts/add_comet_tables.py first."
        )


@pytest.fixture
def sample_fits_file(tmp_path):
    """Create a dummy FITS file for testing uploads."""
    import numpy as np
    from astropy.io import fits

    # Create a simple FITS header
    hdr = fits.Header()
    hdr["EXPTIME"] = 30.0
    hdr["FILTER"] = "R"
    hdr["OBJECT"] = "M31"

    # Create dummy data
    data = np.random.rand(100, 100).astype(np.float32)

    # Create a new FITS HDU
    hdu = fits.PrimaryHDU(data=data, header=hdr)
    hdul = fits.HDUList([hdu])

    # Save to a temporary file
    file_path = tmp_path / "test_image.fits"
    hdul.writeto(file_path, overwrite=True)
    return file_path


# Common test fixtures (consolidated from individual test files)


@pytest.fixture
def sample_location():
    """Shared location fixture for all tests."""
    return {
        "name": "Three Forks, MT",
        "latitude": 45.9183,
        "longitude": -111.5433,
        "elevation": 1234.0,
        "timezone": "America/Denver",
    }


@pytest.fixture
def sample_target():
    """Shared DSO target fixture."""

    from app.models import DSOTarget

    return DSOTarget(
        name="Andromeda Galaxy",
        catalog_id="M31",
        object_type="galaxy",
        ra_hours=0.7122,
        dec_degrees=41.269,
        magnitude=3.4,
        size_arcmin=190.0,
        description="Nearest major galaxy",
    )


@pytest.fixture
def sample_scheduled_target(sample_target):
    """Shared scheduled target fixture."""
    from datetime import datetime

    from app.models import ScheduledTarget

    return ScheduledTarget(
        target=sample_target,
        start_time=datetime(2025, 1, 15, 20, 0),
        end_time=datetime(2025, 1, 15, 23, 0),
        duration_minutes=180,
        start_altitude=45.0,
        end_altitude=60.0,
        max_altitude=65.0,
        field_rotation_deg=15.0,
    )


# ==========================================
# Seestar Playback Testing Fixtures
# ==========================================


@pytest.fixture
def seestar_recorder():
    """Fixture for recording live telescope sessions.

    Usage:
        async def test_record_session(seestar_recorder):
            async with seestar_recorder.intercept_connection("192.168.2.47", 4700) as addr:
                client = SeestarClient()
                await client.connect(addr[0], addr[1])
                # Perform operations
            seestar_recorder.save("tests/fixtures/recordings/my_test.json")
    """
    from tests.fixtures.seestar_recorder import SeestarSessionRecorder

    return SeestarSessionRecorder()


@pytest.fixture
async def playback_server(request):
    """Fixture that loads recording by pytest marker.

    Usage:
        @pytest.mark.recording("goto_success.json")
        async def test_goto(playback_server):
            host, port = playback_server
            client = SeestarClient()
            await client.connect(host, port)
            # Test operations
    """
    from tests.fixtures.seestar_playback import SeestarPlaybackServer

    marker = request.node.get_closest_marker("recording")
    if not marker:
        pytest.skip("No recording specified - use @pytest.mark.recording('filename.json')")

    recording_name = marker.args[0]
    recording_path = Path(__file__).parent / "fixtures" / "recordings" / recording_name

    if not recording_path.exists():
        pytest.skip(f"Recording not found: {recording_path}")

    playback = SeestarPlaybackServer.from_recording(str(recording_path))
    address = await playback.serve()

    yield address

    await playback.stop()


@pytest.fixture
async def seestar_client_with_playback(playback_server):
    """Connected SeestarClient using playback server.

    Usage:
        @pytest.mark.recording("goto_success.json")
        async def test_goto(seestar_client_with_playback):
            client = seestar_client_with_playback
            success = await client.goto_target(10.0, 45.0, "M31")
            assert success
    """
    from app.clients.seestar_client import SeestarClient

    host, port = playback_server
    client = SeestarClient()
    await client.connect(host, port)

    yield client

    await client.disconnect()


# ==========================================
# Real Telescope Hardware Testing
# ==========================================


def pytest_addoption(parser):
    """Add custom pytest command line options for telescope hardware testing."""
    import os

    parser.addoption(
        "--real-hardware",
        action="store_true",
        default=False,
        help="Run tests against real telescope hardware (CAUTION: requires actual telescope)",
    )
    parser.addoption(
        "--telescope-host",
        action="store",
        default=os.environ.get("TELESCOPE_HOST", "192.168.2.47"),
        help="Telescope IP address for real hardware tests",
    )
    parser.addoption(
        "--telescope-port",
        action="store",
        type=int,
        default=int(os.environ.get("TELESCOPE_PORT", "4700")),
        help="Telescope port for real hardware tests",
    )


@pytest.fixture(scope="session")
def real_hardware(request):
    """Check if running in real hardware mode."""
    return request.config.getoption("--real-hardware")


@pytest.fixture(scope="session")
def telescope_host(request):
    """Get telescope host from command line or environment."""
    return request.config.getoption("--telescope-host")


@pytest.fixture(scope="session")
def telescope_port(request):
    """Get telescope port from command line or environment."""
    return request.config.getoption("--telescope-port")
